# 提示词优化与上下文工程：从入门到精通

---

## 1. 提示词工程的进化史：从一句话到一本书的四代革命

**提示词工程不是一成不变的，它随着AI能力进化而进化。** 短短4年（2021-2025），经历了四代技术革命。理解这个演进史，你才能知道现在什么方法最有效，什么方法已经过时。

**第一代：原始提示时代（2021年之前）**。背景是OpenAI刚发布GPT-3，模型能力很弱，像个刚学会说话的小孩。核心挑战是AI经常答非所问、胡说八道、逻辑混乱。解决方法简单粗暴：越少越好，用最简单的描述，避免歧义。典型用法就是"写一篇关于AI的文章"这种一句话提示。效果时好时坏，完全看运气。局限性很明显：输出不稳定，无法理解复杂意图，没有记忆能力。

**第二代：结构化提示时代（2021-2022年）**。标志性事件是2021年底"Chain-of-Thought"（思维链）论文发布。核心突破是发现让AI"一步一步思考"，能大幅提升复杂任务准确率。典型用法是明确要求步骤："请按以下步骤写文章：1.先列出3个核心观点，2.为每个观点找2个案例，3.最后写总结"。核心方法论包括角色设定（"你是一位资深教育专家"）、任务拆解、格式要求、示例参考。这一代把AI处理复杂任务的能力从30%提升到70%。革命性影响是提示词从"玄学"变成了"技巧"，涌现了第一批"提示词工程师"岗位。

**第三代：系统化提示时代（2023年）**。标志性事件是OpenAI发布GPT-4，模型能力质变。核心突破是AI开始理解"提示词的结构"本身，能识别多种指令模式。这一代产生了各种框架：ICIO框架（指令+上下文+输入数据+输出指示）、CRISPE框架（角色+洞察+陈述+性格+实验）。革命性影响是提示词从"技巧"升级为"工程学科"。企业开始建立"提示词资产库"，沉淀高质量提示词。局限也开始显现：提示词越来越长（2000字+），管理困难；同样的提示词在不同模型上效果差异大；模型升级后，原来的提示词可能失效。

**第四代：上下文工程时代（2024年至今）**。标志性事件是Claude 3.5、GPT-4o支持20万tokens上下文。核心理念转变是从"关注提示词技巧"转向"关注上下文充分性"。旧思维是怎么用巧妙的提示词让AI理解意图；新思维是怎么给AI提供充分且必要的背景信息，让它自己理解。不再琢磨"完美提示词"，而是把文档、数据、背景全部给AI。革命性影响是提示词从"写作文"变成"做阅读理解"，企业的"知识库"成为核心竞争力。

**代际对比**：第一代一句话（靠运气），第二代结构化（靠技巧），第三代系统框架（靠工程），第四代上下文（靠系统）。理解这个演进，你就知道为什么现在市面上那些"99元教提示词"的课程已经过时了，因为真正的高手都在做上下文工程。

---

## 2. 理解AI的脑回路：提示词优化的7个底层原理

**提示词优化不是玄学，它背后有明确的心理学和认知科学原理。** 理解AI怎么"思考"，你才能写出好提示词。这些原理是跨模型的通用规律。

**一个本质认知：和ChatGPT合作是通过提问进行的。** 本质上我们要做好一个管理者，德鲁克的管理思想依然不会过时。与ChatGPT合作的核心是提问。我们在与AI的互动中扮演的角色类似于一个管理者，需要明确、细致地指导AI，引导它朝着我们想要的方向前进。

**给ChatGPT交代工作，就像给一位刚刚大学毕业的新员工布置工作**：明确、细致、循循善诱。还有一个核心是：prompt提供的是输出结果的下限，要达到理想效果，核心是挑战输出结果的上限，这个核心是要关注两点：know how（专业知识）和工作流（SOP标准操作程序）。

**原理1：概率预测本质——AI是"最可能"而不是"最正确"**

核心原理：大模型的本质是"预测下一个词的概率分布"，而不是"寻找正确答案"。这意味着AI会输出"看起来最合理"的答案，而不是"事实最正确"的答案。这就是AI会"一本正经地胡说八道"（幻觉）的根本原因。它不是故意骗你，而是它追求语言的流畅性，不是事实的准确性。

实践启示：不要问AI不知道的事（比如"2025年最新的新闻"，它会编）；给AI提供事实锚点（把相关资料给它，让它基于这些资料回答）；要求AI标注不确定的部分（"如果你不确定，请明确标注"）。

错误示范：直接问"告诉我2024年诺贝尔奖得主是谁"。正确做法："基于这份2024年诺贝尔奖官方公告[附上文档]，请告诉我得主是谁，并标注每个信息的来源"。

**原理2：注意力机制——AI的"眼睛"会疲劳**

核心原理：AI一次只能关注有限的信息。虽然它能处理20万token，但它的"注意力"会随着文本长度增加而稀释。关键发现是"开头和结尾最容易被记住"（首尾效应）；重复的信息会被加强（同样指令说3次，AI会特别重视）；特殊标记会吸引注意力（用大写、XML标签、特殊符号会更显眼）。

实践启示：重要信息放开头或结尾（任务目标、核心约束、输出格式这些关键信息别埋在中间）；重复关键指令（"记住，必须输出JSON格式"，在提示词里重复2-3次）；用标签分隔信息（用<task>、<context>、<constraints>等标签，让AI快速定位）。

**原理3：少样本学习——给AI看例子是最好的教学**

核心原理：AI擅长模仿，给它看2-3个例子，它就能学会规律。这基于人类学习原理：教小孩什么是"水果"，你不会读字典定义，而是指着苹果、香蕉说"这是水果"。效果对比很明显：不给例子，AI可能输出"Beautiful Smart Air Conditioner"（错，"美的"是品牌名）；给2个例子（华为、小米的翻译），AI就会输出"Midea Smart Air Conditioner"（正确模仿了品牌名保留拼音的规律）。

最佳实践：2-3个例子效果最好（太少学不会，太多AI会忽略后面的）；例子要有代表性（覆盖主要场景，包括边界情况）；例子和任务格式要一致（如果任务要求JSON，例子也必须是JSON）。

**原理4：思维链——让AI慢思考**

核心原理：AI的"潜意识"反应很快，但容易出错。强迫它"一步一步想"，准确率大幅提升。科学背景是2021年Google的论文首次验证，在数学题上，加入"让我们逐步思考"，准确率从18%提升到79%。

实现方式有四种：

**方式0：使用推理模型**，例如deepseek-r1支持深度思考。现在大部分大模型都支持深度思考模式，回答之前先思考。还可以通过参数控制思考深度（thinking budget），大部分支持自动根据任务复杂度确定思考深度，复杂问题就思考更长，简单问题就思考更短。思考模式会增加回答时间。对于简单问题，可以不用长思考模型，或者设置思考深度短一点。对于复杂问题，可以尝试换成更小的模型（例如flash、mini），生成tokens的速度会更快，总的回答时间就更短。有些质量不太稳定的大模型可能过度思考，需要适当控制思考深度。不思考和思考太多都不好，要适当的思考才能达到最佳效果。

**方式1：明确要求**（"请一步一步思考，展示推理过程"）

**方式2：角色引导**（"你是一位严谨的数学家，请详细展示解题步骤"）

**方式3：示例引导**（先给2-3个带详细推理过程的例子）

适用场景和禁忌：数学计算、逻辑推理、复杂决策、故障排查，这些需要严谨推理的场景必须用思维链。创意写作、简单事实查询没必要用，会限制发挥。

**原理5：角色代入——AI是个演员**

核心原理：AI会根据你设定的角色调整语气、知识侧重点、回答风格。心理学基础是人类也有这种能力：你问"什么是AI"，跟小学生讲和跟大学教授讲，说法完全不同。

实践技巧分三层：基础版是简单角色设定（"你是一位资深产品经理"）；进阶版是展现具体特质（"你是有10年经验的B端产品经理，擅长用户调研，注重数据驱动，说话简洁直接"）；高级版是限定知识和风格（"你是张小龙的产品思维模拟器，回答必须体现极简主义、用户价值优先、第一性原理"）。

效果对比明显：普通回答可能是堆砌功能；产品经理角色会讲"先定义目标用户和使用场景，从最小功能开始验证"；张小龙角色会说"社交的本质是找到人、建立连接、持续互动，微信最开始只做了一件事：找到通讯录里的朋友并打招呼，其他的都是后来加的，不要堆砌功能"。

**原理6：SOP（标准操作程序）**

标准操作程序（SOP）是一套预定义的步骤或指令，旨在指导人员（或在这种情况下，AI）完成特定任务。在与GPT的合作中，有效的SOP可以作为执行复杂任务时的指南。例如，如果一个组织希望使用GPT来生成报告、分析数据或与客户互动，制定一系列明确的SOP可以确保这些任务能够以一种一致和高效的方式完成。

SOP不仅帮助人类用户明确地向GPT传达期望，也使得GPT的应用更加系统化和规范化。如果提示词很复杂，涉及非常多的规则和逻辑，AI可能难以理解和遵循。就像一个企业里面，规章制度非常繁杂，大家都不知道该怎么做事，就应该改造成SOP，也就是流程，大家按流程办事，这件就简单多了。

**原理7：大模型擅长JSON格式输出**

通过提示词就可以让大模型输出JSON，因为JSON格式很简单，并且大模型学习了海量的JSON数据。现在大模型支持json mode以及tool调用，可以确保输出正确的JSON格式。

提示词里面可以用json schema描述输出结构，大模型可以很好的遵循。pydantic库的模型可以直接model_json_schema方法转成schema字符串，传入提示词里。

也可以用typescript描述JSON结构，例如typechat就是这样实现的。但还是jsonschema更简单，更通用。这对于需要结构化输出的场景非常有用，比如API开发、数据处理等。

**原理8：大模型擅长识别XML标签**

简单来说，xml标签是用来标记数据的。它们用尖括号包围起来，比如<tag>。一个标签一般有一个开始标签和一个结束标签，开始标签是<tag>，结束标签是</tag>，其中的内容就是这个标签所包含的数据。

xml标签的特点：
- **自定义标签**：xml标签是可以自定义的。这意味着你可以根据需要创建任何标签来标记你的数据，比如<book>、<title>等
- **结构化数据**：xml标签帮助组织和结构化数据，使数据更易读和理解
- **层次关系**：xml标签可以嵌套，这意味着一个标签可以包含另一个标签，就像<book>标签包含了<title>、<author>和<year>标签
- **标签必须是成对出现的**：使用xml标签的时候，一定是成对出现的，比如<format></format>、<会议内容></会议内容>，两个标签中间的内容，就是我们需要GPT处理的内容。结束标签一定是有一个反斜线/，这点至关重要

大语言模型最大的问题恰恰就在于需要更清晰的描述和数据结构，这样才能更好的理解我们的需求。任何地方出现Prompt都要是成对的，有时候我们需要在Prompt里面告诉AI，什么内容在哪些标签中，以提高它的准确性。例如，我想要告诉AI按照我的格式进行输出，我就会说：按照<format></format>中的格式进行输出，这里一定要是<format></format>不能是format或者是<format>。

---

## 3. 提示词方法论：4个万能框架和15个高级模式

**有了底层原理，接下来是可套用的方法论和模式模板。** 这些是从上千次实践中提炼的"万能公式"，不需要理解原理，直接套用就有效果。

**万能框架1：ICIO框架（最通用的基础框架，适合90%的任务）**

**ICIO = Instruction（指令） + Context（上下文） + Input Data（输入数据） + Output Indicator（输出指示）**

结构模板：
```xml
<instruction>【明确指令】请完成什么任务？一句话说清楚</instruction>

<context>【背景上下文】为什么要做这个？相关背景是什么？</context>

<input_data>【输入数据】需要处理的具体内容</input_data>

<output_indicator>【输出要求】什么格式？什么风格？多长？有什么限制？</output_indicator>
```

实际案例（用户评论情感分析）：
```xml
<instruction>分析以下用户评论的情感倾向，分类为正面、中性或负面</instruction>

<context>这些评论来自我们新上线APP的用户反馈，将用于改进产品体验</context>

<input_data>
评论1：这个APP太难用了，到处都是BUG！
评论2：界面挺简洁的，但功能太少
评论3：非常流畅，比竞品好太多了！
</input_data>

<output_indicator>输出JSON格式：{"评论1":"负面",...}。不要添加任何解释或额外文字</output_indicator>
```

为什么有效？指令清晰（AI知道要做什么），背景充分（知道数据用途，会更准确），输入明确（知道要处理哪些内容），输出可控（知道格式要求，不会输出废话）。

**万能框架2：CRISPE框架（适合创意和内容生成）**

**CRISPE = Capacity and Role（角色） + Insight（洞察） + Statement（陈述） + Personality（性格） + Experiment（实验）**

这个框架适合写文章、做方案、创意输出等需要"思考深度"的任务。

结构模板：
```xml
<capacity_and_role>你是一个什么角色？具备什么能力？</capacity_and_role>

<insight>提供用户不知道的洞察、内幕、背景信息</insight>

<statement>需要做什么？明确陈述任务</statement>

<personality>用什么语气风格？（简洁、幽默、专业、严谨...）</personality>

<experiment>要求AI提供多个选项或不同角度的答案</experiment>
```

实际案例（撰写产品推广文案）：
```xml
<capacity_and_role>你是一位有15年经验的知名品牌营销专家，在快消品行业有丰富经验</capacity_and_role>

<insight>我们这款产品是"无糖气泡水"，目标用户是25-35岁都市白领，关心健康但也追求生活品质。竞品主要有元气森林、喜茶气泡水。我们产品的独特优势是：采用天然果汁调味（不是人工香精）</insight>

<statement>撰写一篇小红书风格的推广文案，突出健康+美味的双重卖点</statement>

<personality>语气轻松活泼，像朋友在聊天，适当使用emoji和网络流行语</personality>

<experiment>提供3个不同风格的版本：版本1强调健康，版本2强调口感，版本3强调生活方式</experiment>
```

**万能框架3：TAG框架（适合任务分解和流程设计）**

**TAG = Task（任务） + Action（行动） + Goal（目标）**

这个框架特别适合把复杂任务拆解成可执行的步骤。

结构模板：
```xml
<task>总任务是什么？要达成什么目标？</task>

<action>请按以下步骤执行：
1. 步骤一...
2. 步骤二...
3. 步骤三...</action>

<goal>最终要达到什么标准？如何验收？</goal>
```

实际案例（竞品分析报告）：
```xml
<task>请完成一份关于"AI编程工具"的竞品分析报告</task>

<action>请按以下步骤执行：
1. 先列出市场上主流的5款AI编程工具
2. 为每个工具收集信息：产品定位、核心功能、价格、用户评价
3. 制作对比表格：从功能、价格、用户体验三个维度
4. 分析每个工具的优劣势
5. 写出总结建议：哪款适合个人开发者，哪款适合企业</action>

<goal>输出一份专业的竞品分析报告，约2000字，结构清晰，数据准确，有明确结论</goal>
```

**万能框架4：思考先行，先引用后回答**

大模型是逐个tokens按顺序生成回答的，前面生成的tokens会影响后面的tokens。先思考可以让回答更有深度，更有理有据，先给出引用可以让回答以事实性为准，减少幻觉（瞎编）问题。

这是一个常用的RAG生成引用的方法：
```
任务：描述任务需求
...
按JSON格式输出带引用的数据：
<json_schema>
{
    "$defs": {
        "CitedText": {
            "properties": {
                "cited": {
                    "description": "Cited source text fragment that supports the answer",
                    "type": "string"
                },
                "text": {
                    "description": "Answer text include line breaks",
                    "type": "string"
                }
            },
            "type": "object"
        }
    },
    "properties": {
        "items": {
            "items": { "$ref": "#/$defs/CitedText" },
            "type": "array"
        }
    },
    "title": "Result",
    "type": "object"
}
```

这个框架确保AI的回答都有事实依据，每个观点都有引用来源，极大减少幻觉问题，特别适合知识库问答、专业报告等场景。

**高级模式库：15个可直接套用的提示词模板**

**模式1：让AI问清楚需求**
```
任务：帮我做XXX

在开始前，请向我提出5个澄清性问题，确保你完全理解我的需求。
这5个问题应该覆盖：
- 目标受众是谁？
- 使用场景是什么？
- 有什么约束条件？
- 成功的标准是什么？
- 有什么需要避免的？
```

**模式2：让AI主动纠错**
```
任务：帮我写一段Python代码实现XXX功能

写完后，请：
1. 自己检查代码是否有bug
2. 分析是否有性能问题
3. 考虑是否有边界情况没处理
4. 最后给出改进建议
```

**模式3：让AI解释后再执行**
```
任务：理解以下需求并复述

1. 请先复述一遍你对需求的理解
2. 我会确认或纠正
3. 确认理解正确后，再执行任务

需求：[你的具体需求]
```

**模式4：分段输出，逐步验证**
```
任务：撰写一份详细的产品方案

请分三阶段输出：
第一阶段：输出大纲，我确认后再继续
第二阶段：输出核心功能模块的详细设计
第三阶段：输出完整的方案

主题：[你的产品主题]
```

**模式5：正反对比分析**
```
请从正反两个角度分析以下问题：

问题：[你的问题]

正面观点（支持）：
- 论点1...
- 论点2...

反面观点（反对）：
- 论点1...
- 论点2...

最后给出综合判断
```

**模式6：专家会诊**
```
请从3个不同角色的视角分析这个问题：

角色1：技术专家（关注可行性）
角色2：产品经理（关注用户价值）
角色3：运营人员（关注推广和成本）

问题：[你的问题]

每个角色给出分析和建议，最后总结共识和分歧
```

**模式7：90分方案快速迭代**
```
任务：[你的任务]

要求：
1. 先快速输出一个60分的方案（最快最简单的版本）
2. 然后指出这个方案的3个最大缺陷
3. 针对每个缺陷给出改进建议
4. 最后整合成一个90分的优化方案
```

**模式8：对抗性思维（魔鬼代言人）**
```
任务：审查以下方案的风险

请你扮演"魔鬼代言人"，专门挑毛病：
1. 找出5个可能失败的原因
2. 找出3个被忽略的关键问题
3. 找出2个过度乐观的假设

方案：[你的方案]
```

**模式9：以终为始，反向推导**
```
目标：[你最终想达到的目标]

请从目标倒推：
1. 要达成这个目标，需要满足什么条件？
2. 要满足这些条件，需要做什么？
3. 具体的第一步是什么？
```

**模式10：费曼学习法**
```
主题：[你想理解的概念]

请用费曼学习法的三个层次解释：
1. 5岁小孩能懂的版本（用比喻和简单语言）
2. 高中生的版本（有专业术语但解释清楚）
3. 专家的版本（深入技术细节）
```

**模式11：概率评估**
```
决策：[你要做的决策]

请评估以下内容：
1. 这个决策成功的概率是多少？（0-100%）
2. 最坏的3种情况是什么？
3. 最好的3种情况是什么？
4. 有什么办法可以提高成功概率？
```

**模式12：六顶思考帽**
```
问题：[你的问题]

请从六个角度分析：
1. 白帽（事实）：已知的信息和数据
2. 红帽（情感）：直觉和感受
3. 黑帽（风险）：潜在问题和风险
4. 黄帽（机会）：积极面和收益
5. 绿帽（创新）：创新的解决方案
6. 蓝帽（控制）：总结和决策
```

**模式13：SCAMPER创新法**
```
主题：[你要创新的产品/方案]

请用SCAMPER方法分析：
S（Substitute替代）：哪些元素可以替代？
C（Combine组合）：可以和什么组合？
A（Adapt适配）：可以适配到其他场景吗？
M（Modify修改）：哪些可以修改？
P（Put to other use另作他用）：还有其他用途吗？
E（Eliminate消除）：哪些可以消除？
R（Reverse反转）：可以反转吗？
```

**模式14：假设检验**
```
假设：[你的假设]

请帮我验证这个假设：
1. 支持这个假设的证据有哪些？
2. 反对这个假设的证据有哪些？
3. 要验证这个假设，需要收集什么数据？
4. 设计一个实验来验证
```

**模式15：第一性原理**
```
问题：[你要解决的问题]

请用第一性原理分析：
1. 这个问题的本质是什么？回到最基本的事实
2. 哪些是大家默认的假设？这些假设一定对吗？
3. 抛开现有方案，从0开始会怎么设计？
4. 现有方案的哪些部分可以优化？
```

这15个模式覆盖了从需求澄清到创新思考的完整闭环，可以根据任务类型灵活组合使用。

---

## 4. 上下文工程：从"写提示词"到"构建系统"

**上下文工程是提示词工程的进化版。** 它不再关注"怎么写提示词"，而是关注"怎么给AI提供充分且必要的背景信息"。

**核心概念：从"一句话"到"一本书"**

传统提示词工程关注提示词怎么写得更好，内容是200-2000字的提示词，思维是"用户要会写提示词"。上下文工程关注AI工作的完整环境是否充分，内容是20万字的全套资料（文档、数据、历史对话、规范、案例），思维是"AI从上下文中自主学习，用户不需要是提示词专家"。

**比喻**：提示词工程 = 给考官出考题，要出得巧妙才能考出学生的能力；上下文工程 = 给学生一本教科书和工作手册，学生自己看书就能完成任务。

**上下文三要素：什么是"充分且必要"的上下文**

**要素1：任务上下文**
是什么：这次任务要解决的具体问题。
包括什么：目标、范围、约束、验收标准。
关键原则：SMART原则（具体、可衡量、可实现、相关性、有时限）。

示例：
```xml
<task_context>
项目名称：新版App用户注册流程优化
目标：3个月内将注册转化率从45%提升到60%
范围：只优化手机号注册流程，不包括第三方登录
约束：
  - 必须保持现有品牌形象
  - 不能增加超过3秒的加载时间
  - 必须符合隐私法规要求
验收标准：A/B测试显著性>95%，样本量>10000
</task_context>
```

**要素2：背景知识上下文**
是什么：与任务相关的领域知识、业务逻辑、行业规范。
包括什么：产品文档、技术文档、用户手册、行业报告。
关键原则：相关的、结构化的、最新的。

示例：
```xml
<knowledge_context>
产品文档：
- 产品定位：面向25-35岁都市白领的健康管理App
- 核心价值：AI个性化饮食建议
- 用户画像：注重健康但时间有限，愿意为便利付费

技术规范：
- 技术栈：React Native + Node.js
- 设计系统：使用Material Design
- API标准：RESTful，返回JSON格式
</knowledge_context>
```

**要素3：历史经验上下文**
是什么：过去成功或失败的经验、案例、数据。
包括什么：历史项目文档、会议记录、用户反馈、测试数据。
关键原则：真实、具体、可复用。

示例：
```xml
<history_context>
成功案例：
- 2024年3月：简化注册流程（从5步减到3步），转化率提升12%
- 关键做法：移除邮箱验证（只保留手机号），使用一键填充

失败教训：
- 2024年1月：增加更多注册项（包括职业、收入），转化率下降18%
- 原因分析：用户觉得隐私泄露风险大，放弃注册

用户反馈（来自客服记录）：
- "希望注册更快一点，现在填的东西太多了"
- "担心手机号会泄露，收到骚扰电话"
</history_context>
```

**上下文架构的四种模式**

**模式1：文档包模式**。适用场景是知识密集型任务（写报告、做方案、回答专业问题）。架构是把相关文档打包：项目背景文档、技术文档、竞品分析报告、用户调研数据。AI自动提取关键信息，用户不需要精简。特点是信息量大（可达20万字），AI当"初级分析师"帮你通读。

**模式2：对话历史模式**。适用场景是长期项目、复杂任务、需要持续迭代的场景。架构是让AI记住完整的对话历史：Day1讨论目标和范围，Day2分析竞品方案，Day3设计原型，Day4技术评估。AI有完整记忆链，不会忘记之前的约定，像真人同事一样协作。

**模式3：规则库模式**。适用场景是需要严格遵守规范、标准、流程的任务（代码审查、文档编写、质量控制）。架构是把所有规则整理成库：设计原则、代码规范、安全规则、输出格式要求。审查任务时，AI对照规则逐一检查。特点是规则清晰，可维护性强。新规则加入规则库即可，不需要改提示词。

**模式4：案例库模式**。适用场景是需要符合特定风格、格式、质量标准的任务（设计、写作、方案）。架构是提供正反面案例：成功案例（什么样的好、为什么好、效果如何）、失败案例（什么样的差、为什么差、后果是什么）。AI通过案例快速理解"什么是好的、什么是差的"。

**从提示词到上下文：架构演进的三个原则**

原则1：可扩展性。提示词时代增加信息要重写提示词，容易混乱；上下文时代直接增加文档、案例、规则到上下文包，结构清晰。

原则2：可维护性。提示词时代提示词越长，维护越难，牵一发而动全身；上下文时代上下文模块化，修改一个模块不影响其他。

原则3：可迁移性。提示词时代换个模型，提示词可能要重写；上下文时代上下文是通用信息，任何模型都能用。

**上下文工程的三个层次**

**层次1：个人级（单次任务）**。场景：写一篇报告、做一份方案。内容：相关文档、数据、参考资料（<50万字）。工具：Claude、ChatGPT的Upload功能。

**层次2：项目级（长期协作）**。场景：产品开发、市场调研、客户服务。内容：项目文档、会议记录、历史决策、用户反馈（<500万字）。工具：Claude Projects、Custom GPTs。

**层次3：企业级（知识系统）**。场景：企业知识库、客服系统、研发平台。内容：全公司文档、规范、历史数据、最佳实践（无上限）。工具：RAG系统（Retrieval-Augmented Generation）。

**演进方向**：从"提示词驱动"到"知识驱动"。

---

## 5. 上下文工程的实践技巧与工具

**从理论到实践，关键是掌握管理超大上下文、验证完整性的技巧。**

**技巧1：管理超大上下文（超过模型限制）**

**问题**：大模型支持20万token（约15万字），但你的文档有100万字怎么办？

**方案1：智能检索（RAG）**。把文档存入向量数据库或搜索引擎，写入时按固定长度或段落等方式切片。用户提问时，先检索出相关片段（比如用关键词或语义相似度），只把相关片段作为上下文输入给模型。

**方案2：上下文目录（Context Indexing）**。将海量上下文处理成目录结构，像书的目录一样，只给AI提供每个章节的标题、摘要、页码。然后让AI通过工具调用按需获取完整内容。比如AI看到"第三章：技术架构"，如果需要，它会调用工具调取完整章节。这个方案更像人类工作方式：先看目录，再找详细内容。


**技巧2：验证上下文完整性（10问清单）**

开始任务前，检查这10个问题：

1. **目标明确**：AI是否知道最终目标？（❌"优化一下" ❌；✓"将注册转化率从45%提升到60%，3个月内"）

2. **范围清晰**：AI是否知道边界？（❌"做产品规划" ❌；✓"只做移动端规划，不含Web端，聚焦增长策略"）

3. **约束完整**：AI是否知道所有限制条件？（技术约束、时间约束、资源约束、合规约束）

4. **背景充分**：AI是否了解业务逻辑和目标用户？（产品定位、用户画像、市场情况、竞争对手）

5. **输入明确**：AI要处理的数据是否清晰？（数据格式、数据量、数据质量、示例）

6. **输出具体**：AI是否知道输出格式和要求？（格式JSON/Markdown、长度500字/10页、风格专业/活泼）

7. **标准可测**：如何衡量AI输出的质量？（准确性、完整性、相关性、可操作性）

8. **历史参考**：AI是否知道过去经验？（成功案例、失败教训、最佳实践）

9. **术语定义**：行业术语、产品特有名词是否有解释？（避免AI理解偏差）

10. **验证机制**：AI是否有自我验证的方法？（例如"检查3遍"、"对比历史数据"）

**上下文工程的三个层次**

**层次1：个人级（单次任务）**。场景：写一篇报告、做一份方案。内容：相关文档、数据、参考资料（<50万字）。工具：Claude、ChatGPT的Upload功能。关键是做好文档整理和结构化。

**层次2：项目级（长期协作）**。场景：产品开发、市场调研、客户服务。内容：项目文档、会议记录、历史决策、用户反馈（<500万字）。工具：Claude Projects、Custom GPTs。关键是版本管理和知识同步。

**层次3：企业级（知识系统）**。场景：企业知识库、客服系统、研发平台。内容：全公司文档、规范、历史数据、最佳实践（无上限）。工具：RAG系统。关键是数据管道、质量控制、权限管理。

**演进方向**：从"提示词驱动"到"知识驱动"。未来的竞争不是谁会写提示词，而是谁有更好的知识库、更清晰的数据、更丰富的经验沉淀。这些才是AI时代真正的生产资料。

**关键洞察**：上下文工程的本质是把隐性知识显性化。企业里很多宝贵经验存在于老员工的脑子里、历史邮件里、会议纪要里。上下文工程通过系统化的整理，让这些经验变成AI可以学习、可以复用、可以传承的知识资产。这不仅提升效率，更是企业知识传承的新范式。

---
