# 提示词优化与上下文工程：从入门到精通

---

## 1. 提示词工程的发展演进

**提示词工程不是一成不变的，它随着AI能力进化而进化。** 从2021年至今，短短四年经历了四代技术革命。

### 第一代：原始提示时代（2021年之前）
**背景**：OpenAI刚发布GPT-3，模型能力很弱，像个刚学会说话的小孩
**核心挑战**：AI经常答非所问、胡说八道、逻辑混乱
**解决方法**：最简单的描述，越少越不容易出错

**典型用法**：
```
写一篇关于AI的文章
```
这种提示词像对待搜索引擎，效果时好时坏，完全看运气。

**局限性**：
- 输出质量不稳定，同样的提示，每次结果差异巨大
- 无法理解复杂意图，稍微复杂点的任务就翻车
- 没有记忆能力，每次对话都是独立的

### 第二代：结构化提示时代（2021-2022年）
**标志性事件**：2021年底，"Chain-of-Thought"（思维链）论文发布
**核心突破**：发现让AI"一步一步思考"，能大幅提升复杂任务的准确率

**典型用法**：
```
请按以下步骤写文章：
1. 先列出3个核心观点
2. 为每个观点找2个案例
3. 最后写一个总结

主题是：AI对教育的影响
```

**核心方法论**：
1. **角色设定**："你是一位资深教育专家"
2. **任务拆解**：把大任务拆成小步骤
3. **格式要求**："用markdown输出"、"分点列出"
4. **示例参考（Few-Shot）**：给AI看1-2个例子，让它模仿

**革命性影响**：
- AI处理复杂任务的能力从30%提升到70%
- 出现了很多"提示词模板"和"提示词库"
- 涌现了第一批"提示词工程师"岗位

### 第三代：提示词工程系统化（2023年）
**标志性事件**：OpenAI发布GPT-4，模型能力质变
**核心突破**：AI开始理解"提示词的结构"本身，能识别多种指令模式

**典型方法论框架**：

**ICIO框架**：
- Instruction（指令）：明确要做什么
- Context（上下文）：提供背景信息
- Input Data（输入数据）：提供素材
- Output Indicator（输出指示）：规定格式

**CRISPE框架**：
- Capacity and Role（角色）："你是一位资深的产品经理"
- Insight（洞察）："提供用户不知道的内幕信息"
- Statement（陈述）："直接给出答案"
- Personality（性格）："用简洁专业的语言"
- Experiment（实验）："给出多个选项"

**革命性影响**：
- 提示词从"技巧"变成"工程学科"
- 出现了系统化的提示词课程（如李一舟的198元课程大火）
- 企业开始建立"提示词资产库"，把好的提示词沉淀下来

**局限显现**：
- 提示词越来越长，2000字的提示词管理困难
- 同样的提示词，在不同模型上效果差异很大（GPT-4效果好，GPT-3.5看不懂）
- 模型升级后，原来的提示词可能失效

### 第四代：上下文工程时代（2024年至今）
**标志性事件**：Claude 3.5、GPT-4o等模型支持20万+ tokens上下文
**核心突破**：AI从"关注提示词技巧"转向"关注上下文充分性"

**核心理念转变**：
- **旧思维**：怎么用巧妙的提示词让AI理解你的意图
- **新思维**：怎么给AI提供充分且必要的背景信息，让它自己理解

**典型用法**：
不再琢磨怎么写"完美提示词"，而是把相关文档、数据、背景全部给AI，让它自己从中理解任务。

**革命性影响**：
- 提示词从"写作文"变成"做阅读理解"
- 企业的"知识库"成为核心竞争力
- 提示词工程从"个人技巧"演变为"系统工程"

**代际对比总结**：
```
第一代：一句话（运气）
第二代：结构化（技巧）
第三代：系统框架（工程）
第四代：上下文（系统）
```

## 2. 提示词优化的基础理论：理解AI的"脑回路"

**提示词优化不是玄学，它背后有明确的心理学和认知科学原理**。理解AI怎么"思考"，你才能写出好提示词。

一个本质：和ChatGPT合作是通过提问进行的。本质是要做好一个管理者，德鲁克依然不会过时。我们需要明白与ChatGPT的合作核心是提问。我们在与AI的互动中扮演的角色类似于一个管理者。就如同管理学之父德鲁克的管理思想所强调的，我们需要明确、细致地指导AI，引导它朝着我们想要的方向前进。

给ChatGPT交代工作，就像给一位刚刚大学毕业的新员工布置工作：明确、细致、循循善诱。还有一个是，prompt提供的是输出结果的下限，要达到理想效果，核心是挑战输出结果的上限，这个核心是要关注两点：know how（公式）和工作流（SOP）。

### 理论1：概率预测本质——AI是"最可能"而不是"最正确"

**核心原理**：大模型的本质是「预测下一个词的概率分布」，而不是「寻找正确答案」。

**这意味着什么**：
- AI会输出"看起来最合理"的答案，而不是"事实最正确"的答案
- 这就是为什么AI会"一本正经地胡说八道"（幻觉）
- 它追求语言的流畅性，而不是事实的准确性

**实践启示**：
- **不要问AI不知道的事**：比如"2025年最新的新闻"，它会编
- **给AI提供事实锚点**：把相关资料给它，让它基于这些资料回答
- **要求AI标注不确定的部分**："如果你不确定，请明确标注"

**错误示范**：
```
错了：告诉我2024年诺贝尔奖得主是谁
对了：基于以下这份2024年诺贝尔奖官方公告[附上文档]，请告诉我得主是谁
```

### 理论2：注意力机制——AI的"眼睛"会疲劳

**核心原理**：AI一次只能关注有限的信息。虽然它能处理20万token，但它的"注意力"会随着文本长度增加而稀释。

**关键发现**：
- **开头和结尾最容易被记住**：这就是所谓的"首尾效应"
- **重复的信息会被加强**：同样指令说3次，AI会特别重视
- **特殊标记会吸引注意力**：用大写、XML标签、特殊符号会更显眼

**实践启示**：
- **重要信息放在开头或结尾**：任务目标、核心约束、输出格式这些关键信息别埋在中间
- **重复关键指令**："记住，必须输出JSON格式"，在提示词里重复2-3次
- **用标签分隔信息**：用<task>、<context>、<constraints>等标签，让AI快速定位

**实际案例**：
```xml
<!-- 好的结构 -->
<task>把用户评论分类为正面、中性、负面</task>
<context>以下是100条用户评论[...]</context>
<constraints>输出必须是JSON格式，且只返回分类结果，不要解释</constraints>

<!-- 差的结构 -->
请帮我分析这些评论，你需要理解每条评论的情感倾向，考虑各种可能的情况，最后给我一个结果。对了，输出JSON格式会更好。以下是我的评论...
```

### 理论3：少样本学习（Few-Shot Learning）——给AI看例子是最好的教学

**核心原理**：AI擅长模仿，给它看2-3个例子，它就能学会规律。

**科学依据**：人类大脑也这样工作。教小孩什么是"水果"，你不会读字典定义，而是指着苹果、香蕉说"这是水果"。

**实践方法**：
```
任务：把中文产品名翻译成英文

示例1：
输入：小米智能手机
输出：Xiaomi Smartphone

示例2：
输入：华为无线耳机
输出：Huawei Wireless Earbuds

现在是你的任务：
输入：美的智能空调
输出：
```

**效果对比**：
- 不给例子：AI可能输出"Beautiful Smart Air Conditioner"（错，"美的"是品牌名）
- 给2个例子：AI会输出"Midea Smart Air Conditioner"（正确模仿了品牌名保留拼音的规律）

**最佳实践**：
1. **2-3个例子效果最好**：太少学不会，太多AI会忽略后面的
2. **例子要有代表性**：覆盖主要场景，包括边界情况
3. **例子和任务格式要一致**：如果任务要求JSON，例子也必须是JSON

### 理论4：思维链（Chain-of-Thought）——让AI慢思考

**核心原理**：AI的"潜意识"反应很快，但容易出错。强迫它"一步一步想"，准确率大幅提升。

**科学背景**：2021年Google的论文首次验证，在数学题上，加入"让我们逐步思考"，准确率从18%提升到79%。

**三种实现方式**：

**方式0: 使用推理模型，例如 deepseek-r1 支持深度思考。**

现在大部分的大模型都支持深度思考模式，回答之前先思考。
还可以通过参数控制思考深度（thinking budget），大部分支持自动根据任务复杂度确定思考深度，复杂问题就思考更长，简单问题就思考更短。

思考模式会增加回答的时间，导致回答变慢了。对于简单问题，可以不用长思考模型，或者设置思考深度短一点。
对于复杂问题，可以尝试换成更小的模型（例如 flash, mini之类的模型），生成tokens的速度会更快，总的回答时间就更短。

有些质量不太稳定的大模型，可能会过度思考，需要控制思考深度。不思考和思考太多都不好，要适当的思考才能达到最佳效果。

**方式1：明确要求**
```
请一步一步思考，展示推理过程：
问题：小明有15个苹果，吃了3个，又买了7个，现在有几个？
```

**方式2：角色引导**
```
你是一位严谨的数学家，请详细展示解题步骤：
问题：计算 (3x + 5) × (2x - 7)
```

**方式3：示例引导**
```
示例：
问题：25 + 37 = ?
解答过程：
1. 先算个位数：5 + 7 = 12，写下2，进1
2. 再算十位数：2 + 3 = 5，加上进位1得6
3. 结果是62

现在请用同样方法计算：48 + 59 = ?
```

**适用场景**：
- ✅ 数学计算、逻辑推理
- ✅ 复杂决策（需要权衡多个因素）
- ✅ 故障排查（需要逐步定位问题）
- ❌ 创意写作（会限制发挥）
- ❌ 简单事实查询（没必要）

### 理论5：角色代入（Persona）——AI是个演员

**核心原理**：AI会根据你设定的角色调整语气、知识侧重点、回答风格。

**心理学基础**：人类也有这种能力。你问"什么是AI"，跟小学生讲和跟大学教授讲，说法完全不同。

**实践技巧**：

**基础版：**
```
你是一位资深产品经理
```

**进阶版：展现具体特质**
```
你是一位有10年经验的B端产品经理，
- 擅长用户调研和需求分析
- 注重数据驱动决策
- 说话简洁直接，不说废话
- 善于发现用户没说出口的隐含需求
```

**高级版：限定知识和风格**
```
你是张小龙（微信产品负责人）的产品思维模拟器。
你的回答必须体现：
1. 极简主义：能少一个功能就少一个，克制是美德
2. 用户价值优先：不为KPI做功能
3. 第一性原理：回到用户最根本的需求
4. 案例支撑：每个观点都要有微信或其他产品的真实案例
```

**效果对比**：
```
问：如何设计一个社交功能？

普通回答：可以加好友、发动态、点赞、评论...

产品经理角色回答：先定义目标用户和使用场景。如果是熟人社交，重点在通讯录导入和关系链沉淀；如果是陌生人社交，重点在匹配算法和破冰机制。建议从最小功能开始验证...

张小龙角色回答：社交的本质是找到人、建立连接、持续互动。微信最开始只做了一件事：找到通讯录里的朋友并打招呼。其他的都是后来加的。你的产品应该解决用户最核心的那个需求，而不是堆砌功能。
```

### 理论6 Know How（专业知识）

专业知识或“know how”是指在特定领域或任务中，人们通过经验和学习获得的实践技能和理解。在与GPT这样的AI工具合作时，“know how”尤为重要。这是因为尽管GPT能够处理大量数据并提供信息，但它缺乏对特定领域的深入理解和实践经验。用户需要利用自己的专业知识来准确地指导GPT，包括但不限于提供详细的背景信息、定义清晰的任务目标和预期结果。这种专业知识的引导能够显著提高GPT输出的质量和相关性。

### 理论7 SOP（标准操作程序）

标准操作程序（SOP）是一套预定义的步骤或指令，旨在指导人员（或在这种情况下，AI）完成特定任务。在与GPT的合作中，有效的SOP可以作为执行复杂任务时的指南。例如，如果一个组织希望使用GPT来生成报告、分析数据或与客户互动，制定一系列明确的SOP可以确保这些任务能够以一种一致和高效的方式完成。SOP不仅帮助人类用户明确地向GPT传达期望，也使得GPT的应用更加系统化和规范化。

如果提示词很复杂，涉及非常多的规则和逻辑，AI可能难以理解和遵循。就像一个企业里面，规章制度非常繁杂，大家都不知道该怎么做事，就应该改造成SOP，也就是流程，大家按流程办事，这件就简单多了。

### 理论9 大模型擅长JSON格式输出

通过提示词就可以让大模型输出JSON，因为JSON格式很简单，并且大模型学习了海量的JSON数据。
现在大模型支持json mode以及tool调用，可以确保输出正确的JSON格式。

提示词里面可以用 json schema 描述输出结构，大模型可以很好的遵循。
pydantic库的模型可以直接 model_json_schema 方法转成 schema 字符串，传入提示词里。

也可以用 typescript 描述JSON结构，例如 typechat 就是这样实现的。但还是jsonschema更简单，更通用。

### 理论9 大模型擅长识别XML标签

简单来说，xml标签是用来标记数据的。它们用尖括号包围起来，比如<tag>。一个标签一般有一个开始标签和一个结束标签，开始标签是<tag>，结束标签是</tag>，其中的内容就是这个标签所包含的数据。

xml标签的特点
自定义标签：xml标签是可以自定义的。这意味着你可以根据需要创建任何标签来标记你的数据，比如<book>、<title>等。
结构化数据：xml标签帮助组织和结构化数据，使数据更易读和理解。
层次关系：xml标签可以嵌套，这意味着一个标签可以包含另一个标签，就像上面的例子中<book>标签包含了<title>、<author>和<year>标签。
标签必须是成对出现的， 使用xml标签的时候，一定是成对出现的，比如<format></format>、<会议内容></会议内容>，两个标签中间的内容，就是我们需要GPT处理的内容。结束标签一定是有一个 反斜线 /，这点至关重要。

大语言模型最大的问题恰恰就在于需要更清晰的描述和数据结构，这样才能更好的理解我们的需求。

任何地方出现Prompt都要是成对的，有时候我们需要在Prompt里面告诉Ai，什么内容在哪些标签中，以提高它的准确性。 例如，我想要告诉Ai按照我的格式进行输出，我就会说：按照 <format></format> 中的格式进行输出，这里一定要是 <format></format> 不能是 format 或者是 <format>。

## 3. 提示词优化的方法论与模式库

**有了理论基础，接下来是可直接套用的方法论和模式模板。** 这些是我从上千次实践中提炼出的"万能公式"。

### 方法论1：ICIO框架（最通用的基础框架）

**ICIO = Instruction（指令） + Context（上下文） + Input Data（输入数据） + Output Indicator（输出指示）**

这个框架适用于90%的任务，是基础中的基础。

**结构模板**：
```xml
<instruction>
【明确指令】请完成什么任务？一句话说清楚
</instruction>

<context>
【背景上下文】为什么要做这个？相关背景是什么？
</context>

<input_data>
【输入数据】需要处理的具体内容
</input_data>

<output_indicator>
【输出要求】什么格式？什么风格？多长？有什么限制？
</output_indicator>
```

**实际案例：用户评论情感分析**
```xml
<instruction>
分析以下用户评论的情感倾向，分类为正面、中性或负面
</instruction>

<context>
这些评论来自我们新上线APP的用户反馈，将用于改进产品体验
</context>

<input_data>
评论1：这个APP太难用了，到处都是BUG！
评论2：界面挺简洁的，但功能太少
评论3：非常流畅，比竞品好太多了！
评论4：客服响应很快，解决问题专业
</input_data>

<output_indicator>
输出JSON格式，如：
{
  "评论1": "负面",
  "评论2": "中性",
  ...
}
不要添加任何解释或额外文字
</output_indicator>
```

**为什么有效**：
1. **指令清晰**：AI知道要做什么（分类任务）
2. **背景充分**：知道数据用途（用户反馈），会更准确
3. **输入明确**：知道要处理哪些具体内容
4. **输出可控**：知道格式要求，不会输出废话

### 方法论2：CRISPE框架（适合创意和内容生成）

**CRISPE = Capacity and Role（角色） + Insight（洞察） + Statement（陈述） + Personality（性格） + Experiment（实验）**

这个框架适合写文章、做方案、创意输出等需要"思考深度"的任务。

**结构模板**：
```xml
<capacity_and_role>
你是一个什么角色？具备什么能力？
</capacity_and_role>

<insight>
提供用户不知道的洞察、内幕、背景信息
</insight>

<statement>
需要做什么？明确陈述任务
</statement>

<personality>
用什么语气风格？（简洁、幽默、专业、严谨...）
</personality>

<experiment>
要求AI提供多个选项或不同角度的答案
</experiment>
```

**实际案例：撰写产品推广文案**
```xml
<capacity_and_role>
你是一位有15年经验的知名品牌营销专家，在快消品行业有丰富经验
</capacity_and_role>

<insight>
我们这款产品是"无糖气泡水"，目标用户是25-35岁的都市白领。
他们关心健康，但也追求生活品质。
竞品主要有元气森林、喜茶气泡水。
我们产品的独特优势是：采用天然果汁调味（不是人工香精）
</insight>

<statement>
撰写一篇小红书风格的推广文案，突出健康+美味的双重卖点
</statement>

<personality>
语气轻松活泼，像朋友在聊天，适当使用emoji和网络流行语
</personality>

<experiment>
提供3个不同风格的版本：
版本1：强调健康
版本2：强调口感
版本3：强调生活方式
</experiment>
```

### 方法论3：TAG框架（适合任务分解和流程设计）

**TAG = Task（任务） + Action（行动） + Goal（目标）**

这个框架特别适合把复杂任务拆解成可执行的步骤。

**结构模板**：
```xml
<task>
总任务是什么？要达成什么目标？
</task>

<action>
请按以下步骤执行：
1. 步骤一...
2. 步骤二...
3. 步骤三...
</action>

<goal>
最终要达到什么标准？如何验收？
</goal>
```

**实际案例：竞品分析报告**
```xml
<task>
请完成一份关于"AI编程工具"的竞品分析报告
</task>

<action>
请按以下步骤执行：
1. 先列出市场上主流的5款AI编程工具
2. 为每个工具收集信息：产品定位、核心功能、价格、用户评价
3. 制作对比表格：从功能、价格、用户体验三个维度
4. 分析每个工具的优劣势
5. 写出总结建议：哪款适合个人开发者，哪款适合企业
</action>

<goal>
输出一份专业的竞品分析报告，约2000字，结构清晰，数据准确，有明确结论
</goal>
```

### 方法论4: 思考先行，先引用后回答

大模型是逐个tokens按顺序生成回答的，前面生成的tokens会影响后面的tokens。
先思考可以让回答更有深度，更有理有据，先给出引用可以让回答以事实性为准，减少幻觉（瞎编）问题。

这是一个常用的RAG生成引用的方法：

```
任务：描述任务需求
...
按JSON格式输出带引用的数据：
<json_schema>
{
    "$defs": {
        "CitedText": {
            "properties": {
                "cited": {
                    "description": "Cited source text fragment that supports the answer",
                    "type": "string"
                },
                "text": {
                    "description": "Answer text include line breaks",
                    "type": "string"
                }
            },
            "type": "object"
        }
    },
    "properties": {
        "items": {
            "items": { "$ref": "#/$defs/CitedText" },
            "type": "array"
        }
    },
    "title": "Result",
    "type": "object"
}
```

### 高级模式库：15个可直接套用的提示词模板

**模式1：让AI问清楚需求**
```
任务：帮我做XXX

在开始前，请向我提出5个澄清性问题，确保你完全理解我的需求。
这5个问题应该覆盖：
- 目标受众是谁？
- 使用场景是什么？
- 有什么约束条件？
- 成功的标准是什么？
- 有什么需要避免的？
```

**模式2：让AI主动纠错**
```
任务：帮我写一段Python代码实现XXX功能

写完后，请：
1. 自己检查代码是否有bug
2. 分析是否有性能问题
3. 考虑是否有边界情况没处理
4. 最后给出改进建议
```

**模式3：让AI解释后再执行**
```
任务：理解以下需求并复述

1. 请先复述一遍你对需求的理解
2. 我会确认或纠正
3. 确认理解正确后，再执行任务

需求：[你的具体需求]
```

**模式4：分段输出，逐步验证**
```
任务：撰写一份详细的产品方案

请分三阶段输出：
第一阶段：输出大纲，我确认后再继续
第二阶段：输出核心功能模块的详细设计
第三阶段：输出完整的方案

主题：[你的产品主题]
```

**模式5：正反对比分析**
```
请从正反两个角度分析以下问题：

问题：[你的问题]

正面观点（支持）：
- 论点1...
- 论点2...

反面观点（反对）：
- 论点1...
- 论点2...

最后给出综合判断
```

**模式6：专家会诊**
```
请从3个不同角色的视角分析这个问题：

角色1：技术专家（关注可行性）
角色2：产品经理（关注用户价值）
角色3：运营人员（关注推广和成本）

问题：[你的问题]

每个角色给出分析和建议，最后总结共识和分歧
```

**模式7：90分方案快速迭代**
```
任务：[你的任务]

要求：
1. 先快速输出一个60分的方案（最快最简单的版本）
2. 然后指出这个方案的3个最大缺陷
3. 针对每个缺陷给出改进建议
4. 最后整合成一个90分的优化方案
```

**模式8：对抗性思维**
```
任务：审查以下方案的风险

请你扮演"魔鬼代言人"，专门挑毛病：
1. 找出5个可能失败的原因
2. 找出3个被忽略的关键问题
3. 找出2个过度乐观的假设

方案：[你的方案]
```

**模式9：以终为始，反向推导**
```
目标：[你最终想达到的目标]

请从目标倒推：
1. 要达成这个目标，需要满足什么条件？
2. 要满足这些条件，需要做什么？
3. 具体的第一步是什么？
```

**模式10：费曼学习法**
```
主题：[你想理解的概念]

请用费曼学习法的三个层次解释：
1. 5岁小孩能懂的版本（用比喻和简单语言）
2. 高中生的版本（有专业术语但解释清楚）
3. 专家的版本（深入技术细节）
```

**模式11：概率评估**
```
决策：[你要做的决策]

请评估以下内容：
1. 这个决策成功的概率是多少？（0-100%）
2. 最坏的3种情况是什么？
3. 最好的3种情况是什么？
4. 有什么办法可以提高成功概率？
```

**模式12：六顶思考帽**
```
问题：[你的问题]

请从六个角度分析：
1. 白帽（事实）：已知的信息和数据
2. 红帽（情感）：直觉和感受
3. 黑帽（风险）：潜在问题和风险
4. 黄帽（机会）：积极面和收益
5. 绿帽（创新）：创新的解决方案
6. 蓝帽（控制）：总结和决策
```

## 4. 上下文工程的理论框架：从提示词到系统

**上下文工程是提示词工程的进化版，它不再关注"怎么写提示词"，而是关注"怎么构建AI工作的完整上下文"。**

### 核心概念：从"一句话"到"一本书"

**传统提示词工程**：
- 关注：提示词怎么写得更好
- 内容：200-2000字的提示词
- 思维：用户要会写提示词

**上下文工程**：
- 关注：AI工作的完整环境是否充分
- 内容：20万字的全套资料（文档、数据、历史对话、规范、案例）
- 思维：AI从上下文中自主学习，用户不需要是提示词专家

**比喻**：
- 提示词工程 = 给考官出考题，要出得巧妙才能考出学生的能力
- 上下文工程 = 给学生一本教科书和工作手册，学生自己看书就能完成任务

### 上下文工程三要素：什么是"充分且必要"的上下文

**要素1：任务上下文**
- **是什么**：这次任务要解决的具体问题
- **包括什么**：目标、范围、约束、验收标准
- **关键原则**：SMART原则（具体、可衡量、可实现、相关性、有时限）

**例子**：
```xml
<task_context>
项目名称：新版App用户注册流程优化
目标：3个月内将注册转化率从45%提升到60%
范围：只优化手机号注册流程，不包括第三方登录
约束：
  - 必须保持现有品牌形象
  - 不能增加超过3秒的加载时间
  - 必须符合隐私法规要求
验收标准：A/B测试显著性>95%，样本量>10000
</task_context>
```

**要素2：背景知识上下文**
- **是什么**：与任务相关的领域知识、业务逻辑、行业规范
- **包括什么**：产品文档、技术文档、用户手册、行业报告
- **关键原则**：相关的、结构化的、最新的

**例子**：
```xml
<knowledge_context>
产品文档：
- 产品定位：面向25-35岁都市白领的健康管理App
- 核心价值：AI个性化饮食建议
- 用户画像：注重健康但时间有限，愿意为便利付费

技术规范：
- 技术栈：React Native + Node.js
- 设计系统：使用Material Design
- API标准：RESTful，返回JSON格式
</knowledge_context>
```

**要素3：历史经验上下文**
- **是什么**：过去成功或失败的经验、案例、数据
- **包括什么**：历史项目文档、用户反馈、测试数据、最佳实践
- **关键原则**：真实、具体、可复用

**例子**：
```xml
<history_context>
成功案例：
- 2024年3月：简化注册流程（从5步减到3步），转化率提升12%
- 关键做法：移除邮箱验证（只保留手机号），使用一键填充

失败教训：
- 2024年1月：增加更多注册项（包括职业、收入），转化率下降18%
- 原因分析：用户觉得隐私泄露风险大，放弃注册

用户反馈（来自客服记录）：
- "希望注册更快一点，现在填的东西太多了"
- "担心手机号会泄露，收到骚扰电话"
</history_context>
```

### 上下文架构的四种模式

**模式1：文档包模式**
**适用场景**：知识密集型任务（写报告、做方案、回答专业问题）

**架构**：
```xml
<task_instruction>
任务：基于以下资料，写一份移动端产品规划
</task_instruction>

<context_package>
  <report_1>2024年产品规划.pdf（50页）</report_1>
  <report_2>竞品分析报告.docx（30页）</report_2>
  <report_3>用户调研数据.xlsx（500条记录）</report_3>
  <report_4>技术架构文档.md（100页）</report_4>
</context_package>

<output_requirement>
输出10页PPT大纲，聚焦用户增长策略
</output_requirement>
```

**特点**：信息量大（可达20万字），AI自动提取关键信息，用户不需要精简

**模式2：对话历史模式**
**适用场景**：长期项目、复杂任务、需要持续迭代的场景

**架构**：
```xml
当前任务：继续优化昨天讨论的注册流程

<conversation_history>
Day1：讨论目标和范围 → 达成：简化手机注册
Day2：分析竞品方案 → 得出：3步注册最佳
Day3：设计第一版原型 → 问题：加载时间太长
Day4：技术评估 → 结论：需要异步加载
</conversation_history>

<current_focus>
今天任务：基于前几天的讨论，输出最终原型设计
</current_focus>
```

**特点**：AI有完整的记忆链，不会忘记之前的约定，像真人同事一样协作

**模式3：规则库模式**
**适用场景**：需要严格遵守规范、标准、流程的任务（代码审查、文档编写、质量控制）

**架构**：
```xml
<task>
审查以下代码是否符合规范
</task>

<code_to_review>
[要审查的代码]
</code_to_review>

<rule_library>
  <design_principles>
    - SOLID原则
    - DRY原则
    - KISS原则
  </design_principles>

  <code_style>
    - 使用ESLint规范
    - 函数不超过50行
    - 注释覆盖关键逻辑
  </code_style>

  <security_rules>
    - 不能有SQL注入风险
    - 敏感信息不能硬编码
    - 输入必须验证
  </security_rules>
</rule_library>

<output_format>
按以下格式输出审查结果：
- 严重问题：...
- 建议优化：...
- 优秀实践：...
</output_format>
```

**特点**：规则清晰，可维护性强。新规则加入规则库即可，不需要改提示词

**模式4：案例库模式**
**适用场景**：需要符合特定风格、格式、质量标准的任务（设计、写作、方案）

**架构**：
```xml
<task>
设计一个新的移动端界面
</task>

<requirements>
目标用户：60岁以上老年人
核心功能：健康数据查看
要求：字体大、操作简单、图标清晰
</requirements>

<example_library>
  <good_example_1>
    成功案例：XX健康App
    特点：字体24px以上，一键查看，图标+文字双重提示
    效果：老年用户日活提升40%
  </good_example_1>

  <good_example_2>
    成功案例：XX医疗App
    特点：语音播报，大按钮设计，容错机制（操作可回退）
    效果：老年用户投诉率下降60%
  </good_example_2>

  <bad_example>
    失败案例：XX健身App
    问题：字体太小、专业术语多、缺少引导
    后果：老年用户留存率<5%
  </bad_example>
</example_library>

<output>
基于以上要求和案例，输出界面设计稿和说明
</output>
```

**特点**：通过正反面案例，AI能快速理解"什么是好的"、"什么是差的"

### 从提示词到上下文：架构演进的三个原则

**原则1：可扩展性**
- **提示词时代**：增加信息要重新写提示词，容易混乱
- **上下文时代**：直接增加文档、案例、规则到上下文包里，结构清晰

**原则2：可维护性**
- **提示词时代**：提示词越长，维护越难，牵一发而动全身
- **上下文时代**：上下文模块化，修改一个模块不影响其他

**原则3：可迁移性**
- **提示词时代**：换个模型，提示词可能要重写
- **上下文时代**：上下文是通用信息，任何模型都能用

### 上下文工程的三个层次

**层次1：个人级（单次任务）**
- 场景：写一篇报告、做一份方案
- 内容：相关文档、数据、参考资料（<50万字）
- 工具：Claude、ChatGPT的Upload功能

**层次2：项目级（长期协作）**
- 场景：产品开发、市场调研、客户服务
- 内容：项目文档、会议记录、历史决策、用户反馈（<500万字）
- 工具：Claude Projects、Custom GPTs

**层次3：企业级（知识系统）**
- 场景：企业知识库、客服系统、研发平台
- 内容：全公司文档、规范、历史数据、最佳实践（无上限）
- 工具：RAG系统（Retrieval-Augmented Generation）

**演进方向**：从"提示词驱动"到"知识驱动"

## 5. 上下文工程的实践技巧与工具

### 技巧：如何管理超大上下文（超过模型限制）

**问题**：大模型支持20万token（约15万字），但我的文档有100万字怎么办？

**方案1：智能检索（RAG）**
用搜索引擎/向量数据库存储所有文档，写入的时候需要按固定长度或者段落等方式切片。
用户提问时，先检索相关信息。
只把相关片段作为上下文，输入给大模型。

**方案2：上下文目录**
将上下文处理成目录结构，像一个文件夹或文档大纲，给大模型提供的是一个目录大纲，只有每个子项的序号/名称/标题/简介内容，不需要全部完整原文。
然后使用 Agent 通过工具调用的方式，先阅读大纲，然后按需调用工具获取相应的原文内容，就像人类看书一样，先看目录，然后翻到具体的页看需要的内容。

### 验证清单：你的上下文工程是否合格

**开始任务前，检查这10个问题**：

1. **目标明确**：AI是否知道最终目标是什么？（SMART原则）
   - ❌ "优化一下"
   - ✓ "将注册转化率从45%提升到60%，在3个月内"

2. **范围清晰**：AI是否知道边界在哪里？
   - ❌ "做产品规划"
   - ✓ "只做移动端规划，不含Web端，聚焦增长策略"

3. **约束完整**：AI是否知道所有限制条件？
   - 技术约束、时间约束、资源约束、合规约束

4. **背景充分**：AI是否了解业务逻辑和目标用户？
   - 产品定位、用户画像、市场情况、竞争对手

5. **输入明确**：AI要处理的数据是否清晰？
   - 数据格式、数据量、数据质量、示例

6. **输出具体**：AI是否知道输出格式和要求？
   - 格式（JSON/Markdown/表格）
   - 长度（500字/2000字/10页PPT）
   - 风格（专业/活泼/严谨）

7. **标准可测**：如何衡量AI输出的质量？
   - 准确性、完整性、相关性、可操作性

8. **历史参考**：AI是否知道过去经验？
   - 成功案例、失败教训、最佳实践
