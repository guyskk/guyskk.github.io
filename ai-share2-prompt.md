# 提示词优化与上下文工程

一套让AI更听话的实战方法。

---

## 1. 提示词工程的进化史

**第一代：原始提示时期（2021-2022）**。GPT-3刚发布，AI能力弱，经常答非所问。核心挑战是输出不稳定、逻辑混乱。提示词策略是越简单越好、避免歧义。ChatGPT问世后，AI能理解自然语言，但输出仍不稳定。**规律：AI能力弱，提示词优化无从谈起。**

**第二代：结构化提示时期（2022-2023）**。2022年初"Chain-of-Thought"（思维链）论文发布，突破是让AI"一步一步思考"，大幅提升复杂任务准确率。产生了角色设定、任务拆解、示例参考等方法。第一批"提示词工程师"岗位出现。**规律：提示词优化变成可复用的技巧。**

**第三代：系统化提示时期（2023-2024）**。GPT-4发布，AI理解能力质变，能识别多种指令模式。催生了ICIO、CRISPE等框架。提示词升级为系统化的"工程学科"。**规律：AI变聪明，能读懂复杂的框架结构。**

**第四代：上下文工程时期（2024-2025）**。Claude 3.5、GPT-4o支持20万tokens上下文，理念彻底转变：从"琢磨完美提示词"转向"提供充分上下文"。旧思维是"出考题"，新思维是"给教科书"。企业"知识库"成为核心竞争力。**规律：AI足够强，上下文足够大，不再依赖于提示词技巧。**

---

## 2. 理解AI的脑回路：7个底层原理

提示词优化不是玄学，是跨模型的通用规律。理解AI怎么"思考"，才能写出好提示词。

**原理1：概率预测本质——AI输出"最可能"而非"最正确"**。大模型本质是"预测下一个词的概率分布"，不是"寻找正确答案"。AI会输出"看起来最合理"而非"事实最准确"的答案，这就是AI"一本正经胡说八道"（幻觉）的根本原因。

不要问AI不知道的事（它会瞎编）；给AI提供事实锚点（把相关资料给它，让它基于这些回答）；要求AI标注引用（"让它提供回答依据"）。

**原理2：注意力机制——AI的"眼睛"会疲劳**。一次只能关注有限信息，有"首尾效应"：开头结尾最容易记住；重复信息会被加强；特殊标记更显眼。实践：重要信息放开头或结尾；重复关键指令2-3次（如"记住，必须输出JSON格式"）；用<task></task>、<output></output>等标签分隔信息。

**原理3：少样本学习——给AI看例子是最好的教学**。AI擅长模仿，给2-3个例子就能学会规律。要点：例子要覆盖主要场景和边界情况；例子格式必须与任务一致。

**原理4：思维链——让AI慢思考**。AI的"潜意识"反应快但易出错，强迫它"一步一步想，给出思考过程"，准确率大幅提升，这就是"Chain-of-Thought"（思维链）。现在的推理模型（如deepseek-r1）本身就支持深度思考，可通过参数控制思考长度。

**原理5：角色代入——AI是个演员**。AI会根据设定的角色和语境调整语气、知识侧重点和回答风格。你问"什么是AI"，小学生与大学教授的说法会截然不同。

**原理6：SOP——把复杂规则变成流程**。复杂提示词涉及过多规则和逻辑，AI难以遵循。就像企业规章制度繁杂，大家不知道怎么做。改造成SOP，按流程办事就简单多了。SOP帮助人类用户明确传达期望，也让AI应用更流程化、规范化。

**原理7：结构化数据格式（JSON和XML）**。大模型学习了海量JSON数据，支持JSON Mode确保格式正确，可以用JSON Schema描述输出结构。同时大模型也擅长识别XML标签，如<tag></tag>，可自定义、结构化、嵌套，用成对标签标记上下文能提高准确性，避免歧义。

---

## 3. 2个实用的提示词框架

从上千次实践中提炼的"万能公式"，直接套用就有效果。

**框架1：ICIO（最通用的基础框架，适合90%任务）**

ICIO = Instruction（指令）+ Context（上下文）+ Input Data（输入数据）+ Output Indicator（输出指示）

结构模板：
```xml
<instruction>【明确指令】请完成什么任务？一句话说清楚</instruction>

<context>【背景】为什么要做这个？相关背景是什么？</context>

<input_data>【输入数据】需要处理的具体内容</input_data>

<output_indicator>【输出要求】什么格式？什么风格？多长？有什么限制？</output_indicator>
```

实战案例（用户评论情感分析）：
```xml
<instruction>分析以下用户评论的情感倾向，分类为正面、中性或负面</instruction>

<context>这些评论来自我们新上线APP的用户反馈，将用于改进产品体验</context>

<input_data>
评论1：这个APP太难用了，到处都是BUG！
评论2：界面挺简洁的，但功能太少
评论3：非常流畅，比竞品好太多了！
</input_data>

<output_indicator>输出JSON格式：{"评论1":"负面",...}。不要添加任何解释或额外文字</output_indicator>
```

精髓：指令清晰（AI知道要做什么），背景充分（知道数据用途，会更准确），输入明确（知道要处理哪些内容），输出可控（知道格式要求，不会输出废话）。

**框架2：CRISPE（适合创意和内容生成）**

CRISPE = Capacity and Role（角色）+ Insight（洞察）+ Statement（陈述）+ Personality（性格）+ Experiment（实验）

这个框架适合写文章、做方案、创意输出等需要"思考深度"的任务。

结构模板：
```xml
<capacity_and_role>你是一个什么角色？具备什么能力？</capacity_and_role>

<insight>提供用户不知道的洞察、内幕、背景信息</insight>

<statement>需要做什么？明确陈述任务</statement>

<personality>用什么语气风格？（简洁、幽默、专业、严谨...）</personality>

<experiment>要求AI提供多个选项或不同角度的答案</experiment>
```

实战案例（撰写产品推广文案）：
```xml
<capacity_and_role>你是一位有15年经验的知名品牌营销专家，在快消品行业有丰富经验</capacity_and_role>

<insight>我们这款产品是"无糖气泡水"，目标用户是25-35岁都市白领，关心健康但也追求生活品质。竞品主要有元气森林、喜茶气泡水。我们产品的独特优势是：采用天然果汁调味（不是人工香精）</insight>

<statement>撰写一篇小红书风格的推广文案，突出健康+美味的双重卖点</statement>

<personality>语气轻松活泼，像朋友在聊天，适当使用emoji和网络流行语</personality>

<experiment>提供3个不同风格的版本：版本1强调健康，版本2强调口感，版本3强调生活方式</experiment>
```

效果：CRISPE框架产出的内容有深度、有洞察、有多样性，不只是机械地完成任务。

---

## 4. 6个可直接套用的提示词模板


**模板1：让AI问清楚需求**
```
任务：帮我做XXX

先复述一遍你的理解和规划，有不懂的和我沟通。
```

**模板2：让AI主动纠错**
```
任务：帮我写一段Python代码实现XXX功能

写完后，请：
1. 仔细review代码，不要有任何坏味道
2. 确保测试100%通过，不要有任何bug
```

**模板3：专家会诊**
```
请从3个不同角色的视角分析这个问题：

角色1：技术专家（关注可行性）
角色2：产品经理（关注用户价值）
角色3：运营人员（关注推广和成本）

问题：[你的问题]

每个角色给出分析和建议，最后总结共识和分歧。
```

**模板4：对抗性思维**
```
任务：审查以下方案的风险

请你扮演"魔鬼代言人"，专门挑毛病：
1. 找出5个可能失败的原因
2. 找出3个被忽略的关键问题
3. 找出2个过度乐观的假设

方案：[你的方案]
```

**模板5：费曼学习法**
```
主题：[你想理解的概念]

请用费曼学习法的三个层次解释：
1. 5岁小孩能懂的版本（用比喻和简单语言）
2. 高中生的版本（有专业术语但解释清楚）
3. 专家的版本（深入技术细节）
```

**模板6：第一性原理**
```
问题：[你要解决的问题]

请用第一性原理分析：
1. 这个问题的本质是什么？回到最基本的事实
2. 哪些是大家默认的假设？这些假设一定对吗？
3. 抛开现有方案，从0开始会怎么设计？
4. 现有方案的哪些部分可以优化？
```

---

## 5. 上下文工程：从"一句话"到"一本书"

上下文工程是提示词工程的进化版。不再关注"怎么写提示词"，而是关注"怎么给AI提供**充分且必要的**上下文信息"。

传统做法是200-2000字提示词，用户需要是"提示词专家"。新做法是20万字全套资料（文档、数据、历史对话、规范、案例），Agent从上下文中自主学习，用户不需要是专家。

比喻：提示词工程=考官出考题，要出得巧妙才能考出学生水平；上下文工程=给学生一本教科书和工作手册，学生自己看书就能完成任务。

---

## 6. 上下文的要素：构建充分且必要的信息

**要素1：任务上下文——这次要解决什么具体问题**

包括：目标（SMART原则：具体、可衡量、可实现、相关性、有时限）、范围、约束、验收标准。

示例：
```xml
<task_context>
项目名称：新版App用户注册流程优化
目标：3个月内将注册转化率从45%提升到60%
范围：只优化手机号注册，不包括第三方登录
约束：保持现有品牌形象、加载时间不超过3秒、符合隐私法规
验收标准：A/B测试显著性>95%，样本量>10000
</task_context>
```

**要素2：背景知识上下文——相关的领域知识、业务逻辑、行业规范**

包括：产品文档、技术文档、用户手册、行业报告。关键原则是相关的、结构化的、最新的。

示例：
```xml
<knowledge_context>
产品文档：
- 产品定位：面向25-35岁都市白领的健康管理App
- 核心价值：AI个性化饮食建议
- 用户画像：注重健康但时间有限，愿意为便利付费

技术规范：
- 技术栈：React Native + Node.js
- 设计系统：使用Material Design
- API标准：RESTful，返回JSON格式
</knowledge_context>
```

**要素3：历史经验上下文——过去成功或失败的经验、案例、数据**

包括：历史项目文档、会议记录、用户反馈、测试数据。关键原则是真实、具体、可复用。

示例：
```xml
<history_context>
成功案例：
- 2024年3月：简化注册流程（从5步减到3步），转化率提升12%
- 关键做法：移除邮箱验证（只保留手机号），使用一键填充

失败教训：
- 2024年1月：增加更多注册项（包括职业、收入），转化率下降18%
- 原因分析：用户觉得隐私泄露风险大，放弃注册

用户反馈（来自客服记录）：
- "希望注册更快一点，现在填的东西太多了"
- "担心手机号会泄露，收到骚扰电话"
</history_context>
```

---
