# AI分享基础篇：理解AI时代的前提和技术基础

---

## 1. 大模型到底是什么：为什么ChatGPT让AI突然变聪明了

大模型本质上是一个超级大脑，通过阅读海量文本学会了理解和生成语言。2022年11月ChatGPT发布后，AI突然像人一样会聊天、写代码、解题，背后就是大模型的功劳。

**核心原理非常简单**：大模型的基础是"预测下一个词"。输入"今天天气很"，它会预测下一个词最可能是"好"、"差"、"不错"。这个预测不是查词典，而是基于看过的几千亿个词，学会了语言规律、知识和逻辑。

**为什么以前没有，2022年才爆发**？三个条件同时成熟：
- 2017年Google发明的Transformer架构解决了长文本理解问题
- GPU芯片不断升级让算力成本降到可接受范围
- 互联网公司积累了20年海量高质量文本数据

**重要认知**：大模型不是搜索引擎，不是数据库，它是一个概率性语言生成器。这意味着它可能"一本正经地胡说八道"（幻觉），也可能创造性地解决问题。

---

## 2. AI产品的三大类型：为什么Agent是下一个金矿

**Chatbot（聊天机器人）**：能力边界是"单次对话"。你问一句，它答一句，每轮对话相对独立。代表产品是最开始的ChatGPT网页版、文心一言、Kimi网页版。适合问答、咨询、简单内容生成。

**Copilot（智能助手）**：能力边界是"人机协作"。AI在旁边辅助，人主导任务。GitHub Copilot（代码补全）、Office Copilot（文档生成）都是典型。特点是高频人机互动：AI生成，人审核修改。人是主驾驶，AI是副驾驶。

**Agent（智能体）**：能力边界是"自主执行"。你给AI一个目标（"帮我调研新能源汽车市场并写份报告"），AI自己拆解任务、搜索信息、分析数据、生成报告。人只负责验收结果，不需要每一步参与。Manus、Claude Code、AutoGPT都是Agent。

Agent的关键特点是**能调用工具**，能和真实世界交互。还有一个核心变化是**反馈循环**，Agent可以借助工具实现反馈循环，AI自己验证、修正、迭代，减少一步错步步错的情况，从而能够独立完成复杂任务。工具调用+反馈循环，是Agent能充分发挥大模型的能力，真正替代人工的关键。

---

## 3. Agent是怎么工作的：从理解目标到完成任务的完整闭环

Agent不是简单的API调用，它是一个能自主思考、规划、执行、反思的系统。理解Agent的工作原理，是设计AI产品的关键。

**Agent工作的四个核心步骤**：

**第一步：理解目标并拆解任务**。说"帮我做个竞品分析"，Agent会先理解目标，自动拆解成：1)确定竞品列表 2)收集每个竞品信息 3)整理对比表格 4)分析优劣势 5)写总结报告。这个过程叫"任务规划"，底层是模型的推理能力。

**第二步：调用工具执行子任务**。Agent知道自己能做什么、不能做什么。对于不能做的事，它会调用工具：搜索引擎查信息、计算器做数学运算、代码解释器运行代码、API查询数据库。工具调用能力让Agent突破了纯文本生成的限制。

**第三步：验证结果并纠正错误**。这是Agent最核心的能力。执行完子任务后，Agent会验证：结果合理吗？数据完整吗？有没有遗漏？发现错误会调整思路重新执行。比如搜索信息时发现结果太少，会换关键词重新搜索。

**第四步：整合输出最终成果**。所有子任务完成后，Agent把碎片信息整合成完整报告，可能还会反思：报告结构清晰吗？重点突出吗？用户会满意吗？有问题会优化后输出。

**关键技术支撑**：
- **工具调用**：大模型被训练成能生成特殊的"工具调用指令"，系统收到后会调用相应API，再把结果返回给模型
- **MCP协议**（模型上下文协议）：Agent和外部工具对话的统一标准。像USB-C接口，任何设备都能插。MCP让Agent能调用任何工具（搜索、数据库、API等），极大扩展能力边界
- **记忆系统**：Agent需要记住做了什么、结果是什么、下一步做什么。通过上下文窗口或外部数据库实现
- **模型能力**：强模型（GPT-5、Claude-4）能一次性完成复杂任务的规划和执行，具备可靠的工具调用能力

---

## 4. RAG是什么：大模型的"查资料"能力

RAG全称是Retrieval-Augmented Generation，中文翻译"检索增强生成"。也就是先查资料，再把查到的资料塞进提示词，让大模型根据资料回答问题。没有RAG时大模型是闭卷考试，只能凭记忆答题；有了RAG是开卷考试，可以现场查书。

#### RAG解决三个核心问题:

**第一，知识时效性**。大模型的知识停留在训练数据截止时间（比如2024年4月），不知道最近发生的事。RAG让大模型能查最新信息，回答"今天的新闻"这种时效性问题。

**第二，领域专业性**。大模型是通才不是专才，不懂你公司的内部规章制度、产品手册、技术文档。RAG把这些专业资料塞进提示词，大模型就能基于这些资料回答专业问题。AI客服、企业内部知识库都是这个原理。

**第三，回答可控性**。大模型容易"一本正经胡说八道"（幻觉），RAG强制它只能基于提供的资料回答， 显著降低胡说八道的概率。这对企业应用至关重要——让AI的回答有据可查，不是凭空编的。

#### RAG的实现

**检索质量是前提**。RAG的核心是"检索"，检索系统可以是搜索引擎、向量数据库、关系型数据库、API接口，只要是"先查后答"都算RAG。但如果检索回来的资料不准、不全、不相关，大模型再强也答不好。

**实现RAG的三要素**：RAG是一个复杂的检索-理解-生成系统。真正有效的RAG需要：精准的检索算法（找到相关的信息）、高质量的知识库（资料准确完整）、提示词工程（让大模型正确使用资料）。三缺其一，效果都会大打折扣。

最简单的RAG实现，就是调用大模型之前，先根据问题检索相关信息，在提示词里加上检索到的信息，让大模型根据这些信息回答问题，这种方式已经能解决很多问题，简单有效。

效果更强的方式，是使用Agent实现，Agent可以调用工具检索信息，如果信息不够，Agent可以自主决定检索更多信息，直到信息足够完成回答。这种多轮检索更像人类的行为，可以应对更复杂的问题。

---

## 5. 模型即Agent（2025）

**趋势：大模型API不只是文本生成，而是会思考、能调工具的Agent系统。**  

**思考：模型能展示完整“思考过程”，使推理透明化。**  
新一代大模型具备“推理链”输出能力。面对复杂问题，它会像人类一样先在内部推演步骤（例如展示数学题的解题过程），再给出最终答案。这不仅提升了结果的可信度，更让开发者能够观察、调试模型的“思路”，为构建可靠Agent提供了关键基础。

**工具：模型能自主调用工具，从“思考”走向“行动”。**  
模型清楚自身局限（如知识过时、无法计算），因此学会了在需要时生成指令，调用搜索引擎、代码解释器或业务API等工具。这使其突破了纯文本的界限，能够处理实时、动态、专业的任务，真正成为能连接现实世界的“行动者”。

**进化：工具调用进入“并行”与“穿插”模式，大幅提升执行速度。**  
早期工具调用是线性的：思考-调用-等待。现在，模型支持：(1) **并行调用**：一次性发起多个无依赖关系的工具请求（如同时读多个文件）；(2) **思考中调用（边想边做）**：在推理中途随时插入工具调用获取关键信息。这极大优化了复杂任务的执行效率。

---

## 6. 大模型全景图（2025）

#### 大模型分类

| 维度    | 类别                      | 特点与适用场景               |               |
|-------|-------------------------|-----------------------|-------------------|
| **尺寸**    | 小模型（<10B）               | 响应快、成本低，轻量任务，手机、IoT设备端侧部署     |         |
|       | 中模型（10-100B）            | 平衡性能与效率，企业通用场景        |            |
|       | 大模型（>100B）              | 智能程度高，复杂任务，MoE架构激活参数约10-70B         |   |
| **模态**    | 纯文本模型                   | LLM基础形态，对话问答，Agent应用               |            |
|       | 多模态模型                   | 支持图像、音频、视频，跨模态理解与生成   |          |
| **开源/闭源** | 开源（如DeepSeek、Qwen） | 权重公开、可私有化部署、支持微调、成本较低 |   |
|       | 闭源（如GPT、Claude）      | 服务稳定、追求极致效果、通常价格较高，API调用为主    |            |

#### 国外主流大模型

| 模型            | 所属公司      | 核心优势          |
|---------------|-----------|----------------------|
| GPT-5        | OpenAI    | 能力强大且均衡，生态成熟  |
| Claude 4.5   | Anthropic | 编程能力顶尖，逻辑推理强  | 
| Gemini 3 Pro | Google    | 多模态能力全面，性价比高  | 
| Grok 4       | xAI      | 内容过滤很少，响应速度快  |


#### 国内主流大模型

| 模型                | 类型    | 特点                       |                                                   |
|--------------------|-------|-----------------------------|----------------------------------------------------------|
| 豆包 Seed       | 闭源    | 综合能力强，多模态齐全            |         |
| 千问 Qwen         | 开源/闭源 | 开源生态活跃，多模态齐全    |         |
| 文心 ERNIE     | 开源/闭源    | 中文写作优势，支持多模态        |         |
| 腾讯 混元     | 开源/闭源  | 多模态和3D能力强             |         |
| DeepSeek    | 开源    | 数学推理顶尖，综合能力强         |              |
| Kimi K2  | 开源    | 长文本、Agent/编程能力强，兼容Claude |  |
| 智谱 GLM      | 开源    | Agent/编程场景优化，兼容Claude         |               |
| MiniMax M2       | 开源    | Agent/编程场景优化，便宜，兼容Claude     |            |

#### 专业视觉模型（专注文档/特定场景）   

- **MinerU 2.5** (上海AI Lab) - SOTA文档解析，1.2B参数 
- **PaddleOCR-VL 3.0** (百度) - 顶尖OCR模型，0.9B参数
- **MiniCPM-V 4.5** (面壁智能) - 端侧最强视觉理解，8B参数 

---

## 7. 大模型的能力边界：适用场景

**AI擅长的**：

**文本处理与生成**：
- 内容创作：文案、文章、代码、创意写作
- 语言转换：翻译、改写、风格调整、格式转换
- 信息提取：总结、关键词提取、结构化整理

**知识问答与推理**：
- 基础推理：逻辑分析、因果关系推断
- 知识整合：跨领域信息综合、概念解释
- 问题解决：基于已有知识的方案设计

**代码相关任务**：
- 代码生成：根据需求编写各种语言的代码
- 调试协助：错误分析、优化建议
- 技术解释：架构设计、算法原理阐述

**产品设计启示**：这些是大模型的"舒适区"，可以作为产品的核心功能点。

**AI难做好的**：

1. 需要"绝对精确性"与"可验证性"的任务——大模型的"幻觉"会导致致命错误

大模型的输出是概率性生成（而非逻辑推导），即使"看起来正确"，也可能包含编造的事实（虚构法条、假数学公式、错误代码）。这类任务的核心要求是"100%准确"，一旦出错会引发严重后果，因此大模型只能做"辅助建议"，不能作主。

2. 需要"高隐私保护"的任务——大模型的"数据泄露风险"不可控

大模型的推理通常需要将数据发送到云端（除非是本地部署的小模型，但小模型能力有限），用户的敏感数据（医疗记录、财务信息）一旦上传，可能因"模型记忆"或"数据泄露"被滥用。

3. 需要"低成本、高频次"的简单任务——大模型的"性价比"太低

大模型的推理成本很高（GPT-4调用成本约0.03美元/1k tokens，传统API可能只需0.001美元/次），对于"简单、重复性"任务，用大模型是资源浪费。

---
