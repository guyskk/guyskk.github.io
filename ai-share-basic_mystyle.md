# AI分享基础篇：理解AI时代的前提和技术基础

---

## 1. 大模型到底是什么：为什么ChatGPT让AI突然变聪明了

大模型本质上是一个超级大脑，通过阅读海量文本学会了理解和生成语言。2022年11月ChatGPT发布后，AI突然像人一样会聊天、写代码、解题，背后就是大模型的功劳。

**核心原理非常简单**：大模型的基础是"预测下一个词"。输入"今天天气很"，它会预测下一个词最可能是"好"、"差"、"不错"。这个预测不是查词典，而是基于看过的几千亿个词，学会了语言规律、知识和逻辑。

**为什么以前没有，2022年才爆发**？三个条件同时成熟：
- 2017年Google发明的Transformer架构解决了长文本理解问题
- GPU芯片让算力成本降到可接受范围
- 互联网公司积累了20年海量高质量文本数据

**重要认知**：大模型不是搜索引擎，不是数据库，它是一个概率性语言生成器。这意味着它可能"一本正经地胡说八道"（幻觉），也可能创造性地解决问题。

---

## 2. AI产品的三大类型：为什么Agent是下一个金矿

**Chatbot（聊天机器人）**：能力边界是"单次对话"。你问一句，它答一句，每轮对话相对独立。代表产品是最开始的ChatGPT网页版、文心一言、Kimi网页版。适合问答、咨询、简单内容生成。

**Copilot（智能助手）**：能力边界是"人机协作"。AI在旁边辅助，人主导任务。GitHub Copilot（代码补全）、Office Copilot（文档生成）都是典型。特点是高频人机互动：AI生成，人审核修改。人是主驾驶，AI是副驾驶。

**Agent（智能体）**：能力边界是"自主执行"。你给AI一个目标（"帮我调研新能源汽车市场并写份报告"），AI自己拆解任务、搜索信息、分析数据、生成报告。人只负责验收结果，不需要每一步参与。Manus、Claude Code、AutoGPT都是Agent。

Agent的关键特点是**能调用工具**，能和真实世界交互。还有一个核心变化是**反馈循环**，Agent可以借助工具实现反馈循环，AI自己验证、修正、迭代，减少一步错步步错的情况，从而能够独立完成复杂任务。工具调用+反馈循环，是Agent能充分发挥大模型的能力，真正替代人工的关键。

---

## 3. Agent是怎么工作的：从理解目标到完成任务的完整闭环

Agent不是简单的API调用，它是一个能自主思考、规划、执行、反思的系统。理解Agent的工作原理，是设计AI产品的关键。

**Agent工作的四个核心步骤**：

**第一步：理解目标并拆解任务**。说"帮我做个竞品分析"，Agent会先理解目标，自动拆解成：1)确定竞品列表 2)收集每个竞品信息 3)整理对比表格 4)分析优劣势 5)写总结报告。这个过程叫"任务规划"，底层是模型的推理能力。

**第二步：调用工具执行子任务**。Agent知道自己能做什么、不能做什么。对于不能做的事，它会调用工具：搜索引擎查信息、计算器做数学运算、代码解释器运行代码、API查询数据库。工具调用能力让Agent突破了纯文本生成的限制。

**第三步：验证结果并纠正错误**。这是Agent最核心的能力。执行完子任务后，Agent会验证：结果合理吗？数据完整吗？有没有遗漏？发现错误会调整思路重新执行。比如搜索信息时发现结果太少，会换关键词重新搜索。

**第四步：整合输出最终成果**。所有子任务完成后，Agent把碎片信息整合成完整报告，可能还会反思：报告结构清晰吗？重点突出吗？用户会满意吗？有问题会优化后输出。

**关键技术支撑**：
- **工具调用**：大模型被训练成能生成特殊的"工具调用指令"，系统收到后会调用相应API，再把结果返回给模型
- **MCP协议**（模型上下文协议）：Agent和外部工具对话的统一标准。像USB-C接口，任何设备都能插。MCP让Agent能调用任何工具（搜索、数据库、API等），极大扩展能力边界
- **记忆系统**：Agent需要记住做了什么、结果是什么、下一步做什么。通过上下文窗口或外部数据库实现
- **模型能力**：强模型（GPT-5、Claude-4）能一次性完成复杂任务的规划和执行，具备可靠的工具调用能力

---

## 4. RAG是什么：大模型的"查资料"能力

RAG全称是Retrieval-Augmented Generation，中文翻译"检索增强生成"。也就是先查资料，再把查到的资料塞进提示词，让大模型根据资料回答问题。没有RAG时大模型是闭卷考试，只能凭记忆答题；有了RAG是开卷考试，可以现场查书。

#### RAG解决三个核心问题:

**第一，知识时效性**。大模型的知识停留在训练数据截止时间（比如2024年4月），不知道最近发生的事。RAG让大模型能查最新信息，回答"今天的新闻"这种时效性问题。

**第二，领域专业性**。大模型是通才不是专才，不懂你公司的内部规章制度、产品手册、技术文档。RAG把这些专业资料塞进提示词，大模型就能基于这些资料回答专业问题。AI客服、企业内部知识库都是这个原理。

**第三，回答可控性**。大模型容易"一本正经胡说八道"（幻觉），RAG强制它只能基于提供的资料回答， 显著降低胡说八道的概率。这对企业应用至关重要——让AI的回答有据可查，不是凭空编的。

#### RAG的实现

**检索质量是前提**。RAG的核心是"检索"，检索系统可以是搜索引擎、向量数据库、关系型数据库、API接口，只要是"先查后答"都算RAG。但如果检索回来的资料不准、不全、不相关，大模型再强也答不好。

**实现RAG的三要素**：RAG是一个复杂的检索-理解-生成系统。真正有效的RAG需要：精准的检索算法（找到相关的信息）、高质量的知识库（资料准确完整）、提示词工程（让大模型正确使用资料）。三缺其一，效果都会大打折扣。

最简单的RAG实现，就是调用大模型之前，先根据问题检索相关信息，在提示词里加上检索到的信息，让大模型根据这些信息回答问题，这种方式已经能解决很多问题，简单有效。

效果更强的方式，是使用Agent实现，Agent可以调用工具检索信息，如果信息不够，Agent可以自主决定检索更多信息，直到信息足够完成回答。这种多轮检索更像人类的行为，可以应对更复杂的问题。

---

## 5. 目前的AI大模型全景图

#### 大模型分类

大模型可以按尺寸分成不同的档位，从1B 到 1000B都有，通常10B以内的是小模型，10B-100B属于中等，100B以上是大模型。

可以按输入输出类型，分成语言大模型，视觉大模型，除此之外还有，图像生成、语音生成、音乐生成、视频生成、数字人之类的模型。

开源vs闭源，模型权重公开的叫做开源模型，任何人都可以部署，可私有化部署（数据不出内网）、可微调定制。劣势是模型性能稍弱一些，开源模型正在快速追赶。DeepSeek V3.2、Kimi K2的性能已经超越GPT-4，接近顶尖闭源模型。

#### 国外模型

Openai GPT5 实际对应内部多个大小的模型，以及不同的推理强度，智能程度高，能力均衡。最新的 Code 模型适合写代码，配合 codex 使用和 claude 不相上下。

Claude 4 Opus超大杯/Sonnet大杯/Haiku中杯，常用Sonnet 4.5，写代码能力顶尖，价格很贵，比 GPT 更贵。

Gemini 3 Pro，前端代码能力很强，综合表现很好，价格相对便宜。实际问答体验不如GPT和Claude，对中文支持不是很好。

Grok 4 / code fast 1，马斯克 xAI的模型，智能程度比上面几家稍差，但可能是算力比较足，生成速度很快。code fast 1 在 openrouter 上面长期霸榜，可能是价格非常便宜。


#### 国产模型

豆包 Seed 1.6 / thinking / flash，闭源，智能程度高，，服务稳定，很便宜，种类齐全（各种大小，各种模态都有）

阿里千问，闭源模型和豆包差不多，可以全方位对标豆包。Qwen开源模型很知名，但智能程度不如Deepseek, Kimi K2，开源的qwen小模型适合私有化部署，用于处理简单任务。

百度文心，闭源模型，智能程度稍差一些，中文写作能力有优势，适合写作、知识问答场景。

Deepseek，开源，老版本V3和R1已经逐渐被淘汰了，最新的 V3.2 版本，智能程度高，尤其是数学竞赛很强，整体水平接近GPT5。

月之暗面，最新的 Kimi K2 / Kimi K2 Thinking 开源，智能程度高，适合写代码，对标 Claude 4。有Turbo版模型生成速度很快，智能程度和开源一致，但价格贵很多。

智谱 最新的 GLM 4.6 和Kimi K2类似，智能程度也很高，比Kimi便宜，适合写代码，对标 Claude 4。

MiniMax M2，开源，价格非常便宜，适合写代码，对标 Claude 4，智能程度稍差一些。

#### 视觉和OCR模型

大模型的视觉理解是很重要的能力（看图说话能力），尤其是在 RAG 的场景，需要让大模型能理解各种文档，里面常常会有图片表格需要视觉能力才能理解。有些大模型会自带视觉理解，例如 豆包 seed，千问模型。也有一些专门的视觉理解模型，主要是小模型，适合私有化部署。

百度旗下 PaddleOCR ，这个是老牌的OCR产品，现在也升级为视觉大模型，效果是顶尖水平。

MinerU 2.5，最新的文档解析产品，内部有视觉大模型，效果非常好。

GLM 4.5V 视觉模型，没体验过。

MiniCPM 很有名，没体验过。

---

## 6. 探讨大模型的技术趋势

#### 短期突破：深度思考+工具调用=Agent能力升级

深度思考能力，工具调用能力，边思考边调用工具，一次批量调用多个工具。

服务端工具，模型厂商预置工具，比如搜索引擎、知识库等，大模型即Agent。

#### 长期趋势：推理成本持续下降，推理速度越来越快

推理成本 Transformer 是 O(n^2) 复杂度，Deepseek 稀疏注意力 近似线性 把n^2 降到 n*k，其中k远小于n ，从而实现近线性复杂度 O(n * Log (n))，成本更低，尤其是生成很长的文本时。

Deepseek提出的视觉tokens，OCR模型，MinerU2.5 的 vlm 小模型表现很好，似乎指向了一个方向：视觉tokens比语言tokens更高效。文字也许可以用视觉的方式更高效表示。

模型如果保持智能程度不变，但体积不断缩小，也就是计算量不断减少，再叠加推理方面的优化，硬件方面的性能提升，大模型的推理速度会越来越快。

#### 大模型记忆：著名的病人H.M.（亨利）

分享故事，补充一个特殊的脑科学病人，对脑科学/认知科学有重大意义，他没有长期记忆，只有短期记忆。但是他有事故以前的长期记忆。

他是 H.M.（亨利），历史上最重要、被研究得最彻底的脑科学病例之一。
1953年，27岁的亨利在康涅狄格州哈特福德医院接受了双侧内侧颞叶切除术，以治疗严重的、药物无法控制的癫痫。亨利的手术切除了大脑双侧的内侧颞叶结构，包括海马体、海马旁回和杏仁核的大部分。

手术成功地减轻了亨利的癫痫症状，但带来了一个灾难性且意想不到的后果：他患上了一种极其严重的顺行性遗忘症，并伴有部分逆行性遗忘症。

顺行性遗忘症（无法形成新的长期记忆）：
这是亨利最核心的特征。手术几乎完全剥夺了他将短期记忆转化为长期记忆的能力。
他的短时记忆（持续约20-30秒）和工作记忆（在脑中暂时处理信息） 是完好的。他可以进行正常的对话，只要话题不超出他短时记忆的容量。
然而，一旦注意力转移（比如谈话中断或他离开房间），他对刚刚发生的事件、对话或遇到的人毫无记忆。他永远生活在“当下”，记忆仿佛被不断重置。

现在的大模型，就是和亨利的大脑很像，没有长期记忆，需要通过外部工具（就像记笔记一样），才能记住长期的东西。
大模型的长期记忆应该是一个独立的系统，目前有很多工具例如 [Mem0](https://github.com/mem0ai/mem0) 可以实现长期记忆，我们应该借助工具实现长期记忆，而不是期望大模型的上下文窗口无限增大。

---

## 7. 大模型的能力边界：适用场景

**AI擅长的**：

**文本处理与生成**：
- 内容创作：文案、文章、代码、创意写作
- 语言转换：翻译、改写、风格调整、格式转换
- 信息提取：总结、关键词提取、结构化整理

**知识问答与推理**：
- 基础推理：逻辑分析、因果关系推断
- 知识整合：跨领域信息综合、概念解释
- 问题解决：基于已有知识的方案设计

**代码相关任务**：
- 代码生成：根据需求编写各种语言的代码
- 调试协助：错误分析、优化建议
- 技术解释：架构设计、算法原理阐述

**产品设计启示**：这些是大模型的"舒适区"，可以作为产品的核心功能点。

**AI难做好的**：

1. 需要"绝对精确性"与"可验证性"的任务——大模型的"幻觉"会导致致命错误

大模型的输出是概率性生成（而非逻辑推导），即使"看起来正确"，也可能包含编造的事实（虚构法条、假数学公式、错误代码）。这类任务的核心要求是"100%准确"，一旦出错会引发严重后果，因此大模型只能做"辅助建议"，不能作主。

2. 需要"高隐私保护"的任务——大模型的"数据泄露风险"不可控

大模型的推理通常需要将数据发送到云端（除非是本地部署的小模型，但小模型能力有限），用户的敏感数据（医疗记录、财务信息）一旦上传，可能因"模型记忆"或"数据泄露"被滥用。

3. 需要"低成本、高频次"的简单任务——大模型的"性价比"太低

大模型的推理成本很高（GPT-4调用成本约0.03美元/1k tokens，传统API可能只需0.001美元/次），对于"简单、重复性"任务，用大模型是资源浪费。

---
